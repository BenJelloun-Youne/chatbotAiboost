import streamlit as st
from openai import OpenAI
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_core.messages import AIMessage, HumanMessage
import pandas as pd
import re
import time
import random
from datetime import datetime
import streamlit.components.v1 as components
import os
import sqlite3
import openai

# Configuration de la page
st.set_page_config(
    page_title="Assistant KPIs",
    page_icon="üìä",
    layout="wide"
)

# Th√®me sombre Streamlit (optionnel, d√©pend de la config utilisateur)
st.markdown("""
    <style>
        .stApp { background-color: #1e1e1e; color: #d4d4d4; }
        .css-1v0mbdj, .css-1d391kg { background: #252526 !important; }
        .stTextInput>div>div>input {
            background-color: #2d2d2d;
            color: #d4d4d4;
            border: 1px solid #3c3c3c;
            border-radius: 0.5rem;
            padding: 1rem;
        }
        .stTextInput>div>div>input:focus {
            border-color: #007acc;
            box-shadow: 0 0 0 2px rgba(0, 122, 204, 0.2);
        }
        .stButton>button {
            background-color: #2d2d2d;
            color: #d4d4d4;
            border: 1px solid #3c3c3c;
            border-radius: 0.5rem;
            padding: 0.5rem 1rem;
            margin-bottom: 0.5rem;
            transition: all 0.3s;
        }
        .stButton>button:hover {
            background-color: #3c3c3c;
            border-color: #007acc;
        }
        .user-msg {
            background: #2d2d2d;
            border-left: 4px solid #007acc;
            border-radius: 0.5rem;
            padding: 1rem;
            margin-bottom: 0.5rem;
        }
        .assistant-msg {
            background: #252526;
            border-left: 4px solid #4ec9b0;
            border-radius: 0.5rem;
            padding: 1rem;
            margin-bottom: 0.5rem;
        }
        .timestamp {
            color: #858585;
            font-size: 0.8rem;
            float: right;
        }
        .user-bubble {
            background: #2d2d2d;
            border-left: 4px solid #007acc;
            border-radius: 0.7rem;
            padding: 1rem;
            margin-bottom: 0.5rem;
            max-width: 70%;
            margin-left: auto;
        }
        .assistant-bubble {
            background: #252526;
            border-left: 4px solid #4ec9b0;
            border-radius: 0.7rem;
            padding: 1rem;
            margin-bottom: 0.5rem;
            max-width: 70%;
            margin-right: auto;
        }
        .sidebar-metric {
            background: #252526;
            border-radius: 0.5rem;
            padding: 1rem;
            text-align: center;
            margin-bottom: 0.5rem;
        }
        .sidebar-metric-title {
            color: #858585;
            font-size: 0.9rem;
        }
        .sidebar-metric-value {
            color: #4ec9b0;
            font-size: 1.5rem;
            font-weight: bold;
        }
    </style>
""", unsafe_allow_html=True)

# CSS personnalis√©
st.markdown("""
    <style>
        /* Style g√©n√©ral */
        .stApp {
            background-color: #1e1e1e;
            color: #d4d4d4;
            font-family: 'Consolas', 'Monaco', monospace;
        }
        
        /* Style des messages de chat */
        .chat-message {
            padding: 1rem;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
            transition: all 0.3s ease;
        }
        
        .chat-message:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        
        .chat-message.user {
            background-color: #2d2d2d;
            border-left: 4px solid #007acc;
        }
        
        .chat-message.assistant {
            background-color: #252526;
            border-left: 4px solid #4ec9b0;
        }
        
        .timestamp {
            color: #858585;
            font-size: 0.8rem;
        }
        
        /* Style de la barre lat√©rale */
        .sidebar-section {
            background-color: #252526;
            padding: 1rem;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }
        
        .sidebar-title {
            color: #d4d4d4;
            font-size: 1.1rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid #3c3c3c;
        }
        
        /* Style des statistiques */
        .stats-container {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 1rem;
        }
        
        .stat-item {
            background-color: #2d2d2d;
            padding: 1rem;
            border-radius: 0.5rem;
            text-align: center;
        }
        
        .stat-value {
            display: block;
            font-size: 1.5rem;
            font-weight: bold;
            color: #007acc;
            margin-bottom: 0.5rem;
        }
        
        .stat-label {
            color: #858585;
            font-size: 0.9rem;
        }
        
        /* Style des questions d'exemple */
        .question-category {
            margin-bottom: 1rem;
        }
        
        .question-item {
            background-color: #2d2d2d;
            padding: 0.8rem;
            border-radius: 0.5rem;
            margin-bottom: 0.5rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .question-item:hover {
            background-color: #3c3c3c;
            transform: translateX(5px);
        }
        
        /* Style des boutons */
        .action-button, .tool-button {
            background-color: #2d2d2d;
            color: #d4d4d4;
            border: 1px solid #3c3c3c;
            padding: 0.5rem 1rem;
            border-radius: 0.5rem;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            width: 100%;
            margin-bottom: 0.5rem;
        }
        
        .action-button:hover, .tool-button:hover {
            background-color: #3c3c3c;
            border-color: #007acc;
        }
        
        /* Style de l'input */
        .stChatInput input {
            background-color: #2d2d2d !important;
            color: #d4d4d4 !important;
            border: 1px solid #3c3c3c !important;
            border-radius: 0.5rem !important;
            padding: 1rem !important;
        }
        
        .stChatInput input:focus {
            border-color: #007acc !important;
            box-shadow: 0 0 0 2px rgba(0, 122, 204, 0.2) !important;
        }
        
        /* Animation de r√©flexion */
        .thinking {
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 1rem;
        }
        
        .thinking-dots {
            display: flex;
            gap: 0.5rem;
        }
        
        .thinking-dot {
            width: 8px;
            height: 8px;
            background-color: #007acc;
            border-radius: 50%;
            animation: thinking 1.4s infinite ease-in-out;
        }
        
        .thinking-dot:nth-child(1) { animation-delay: 0s; }
        .thinking-dot:nth-child(2) { animation-delay: 0.2s; }
        .thinking-dot:nth-child(3) { animation-delay: 0.4s; }
        
        @keyframes thinking {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1); }
        }
        
        /* Titres */
        .main-title {
            color: #007acc;
            font-size: 2rem;
            margin-bottom: 0.5rem;
        }
        
        .subtitle {
            color: #858585;
            font-size: 1.1rem;
            margin-bottom: 2rem;
        }
    </style>
""", unsafe_allow_html=True)

# Titre de l'application
st.markdown("""
    <h1 class="main-title">Assistant KPIs</h1>
    <p class="subtitle">Analysez vos donn√©es de performance en temps r√©el</p>
""", unsafe_allow_html=True)

# === Configuration API et base de donn√©es ===
try:
    # Configuration directe de l'API OpenAI
    OPENAI_API_KEY = "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"
    client = OpenAI(api_key=OPENAI_API_KEY)
except Exception as e:
    st.error(f"Erreur lors de l'initialisation de l'API OpenAI : {str(e)}")

# Chemin vers votre base de donn√©es SQLite
try:
    DB_PATH = "call_center_full_extended.db"
    db = SQLDatabase.from_uri(f"sqlite:///{DB_PATH}")
except Exception as e:
    st.error(f"Erreur lors de la connexion √† la base de donn√©es : {str(e)}")

# === Fonctions utilitaires SQL et chat ===

def get_schema(db):
    """R√©cup√®re les informations de sch√©ma de la base de donn√©es."""
    return db.get_table_info()

def format_chat_history(chat_history, max_messages=5):
    """Formate l'historique de chat pour l'inclure dans le prompt."""
    formatted_history = []
    filtered_history = [
        msg for msg in chat_history
        if not (isinstance(msg, AIMessage) and "Bonjour" in msg.content)
    ]
    for message in filtered_history[-max_messages:]:
        role = "Utilisateur" if isinstance(message, HumanMessage) else "Assistant"
        formatted_history.append(f"{role}: {message.content}")
    return "\n".join(formatted_history)

def execute_sql_query(query):
    """Ex√©cute une requ√™te SQL et g√®re les exceptions."""
    try:
        # Nettoyage de la requ√™te
        clean_query = re.sub(r'```sql|```', '', query).strip()
        result = db.run(clean_query)
        
        # Log de d√©bogage
        st.write(f"Requ√™te ex√©cut√©e: {clean_query}")
        st.write(f"R√©sultat brut: {result}")
        
        # V√©rification si le r√©sultat est vide
        if not result:
            return "Aucun r√©sultat trouv√© pour cette requ√™te."
            
        # Conversion du r√©sultat en format texte
        if isinstance(result, list) and len(result) > 0:
            if isinstance(result[0], tuple):
                # Pour les requ√™tes de comptage simples (un seul nombre)
                if len(result) == 1 and len(result[0]) == 1:
                    return str(result[0][0])
                
                # Pour les autres requ√™tes avec plusieurs colonnes
                # Extraction des noms de colonnes de la requ√™te
                column_names = []
                matches = re.findall(r'(?:AS\s+)(\w+)|COUNT\(\*\)\s+(?:AS\s+)?(\w+)', clean_query, re.IGNORECASE)
                if matches:
                    column_names = [m[0] or m[1] for m in matches if m[0] or m[1]]
                else:
                    # Si pas d'alias trouv√©s, extraire les noms des colonnes apr√®s SELECT
                    select_part = clean_query.upper().split('FROM')[0].replace('SELECT', '').strip()
                    columns = [col.strip().split()[-1] for col in select_part.split(',')]
                    column_names = [col.split('.')[-1] for col in columns]
                
                if not column_names:  # Si toujours pas de noms de colonnes, utiliser des noms g√©n√©riques
                    column_names = [f"colonne_{i}" for i in range(len(result[0]))]
                
                # Cr√©ation du r√©sultat format√©
                formatted_result = ",".join(column_names) + "\n"
                for row in result:
                    formatted_result += ",".join(str(value) for value in row) + "\n"
                return formatted_result.strip()
            else:
                return str(result[0])
        else:
            return str(result)
            
    except Exception as e:
        st.error(f"Erreur lors de l'ex√©cution de la requ√™te SQL: {str(e)}")
        return f"Erreur: {str(e)}"

def generate_simple_sql(question, schema):
    """
    G√©n√®re une requ√™te SQL simple bas√©e sur des r√®gles pour les cas communs.
    On se base ici sur des mots-cl√©s pour d√©terminer la requ√™te √† g√©n√©rer.
    """
    question = question.lower().strip()
    
    # Requ√™tes sur les agents
    if any(pattern in question for pattern in ["combien d'agent", "nombre d'agent", "nombre agent"]):
        return "SELECT COUNT(*) FROM agents;"
    
    # Requ√™tes sur les performances des agents
    if (("top" in question and "perform" in question) or 
        ("meilleur" in question and "agent" in question)):
        return """
        SELECT a.agent_id, a.name, t.team_name, 
               SUM(p.sales) as total_sales, 
               SUM(p.appointments) as total_appointments,
               ROUND(AVG(p.satisfaction_score), 2) as avg_satisfaction
        FROM agents a
        JOIN performances p ON a.agent_id = p.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        ORDER BY total_sales DESC
        LIMIT 5;
        """
    
    # Requ√™tes sur les √©quipes
    if ("equipe" in question or "team" in question) and ("performance" in question or "resultat" in question):
        return """
        SELECT t.team_name, 
               COUNT(DISTINCT a.agent_id) as nombre_agents,
               SUM(p.sales) as total_ventes,
               ROUND(AVG(p.satisfaction_score), 2) as satisfaction_moyenne
        FROM teams t
        JOIN agents a ON t.team_id = a.team_id
        JOIN performances p ON a.agent_id = p.agent_id
        GROUP BY t.team_name
        ORDER BY total_ventes DESC;
        """
    
    # Requ√™tes sur les bonus
    if "bonus" in question:
        return """
        SELECT a.name, t.team_name,
               COUNT(b.bonus_id) as nombre_bonus,
               SUM(b.bonus_amount) as montant_total_bonus
        FROM agents a
        JOIN bonuses b ON a.agent_id = b.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        ORDER BY montant_total_bonus DESC
        LIMIT 5;
        """
    
    # Requ√™tes sur la satisfaction client
    if "satisfaction" in question:
        return """
        SELECT a.name, t.team_name,
               ROUND(AVG(p.satisfaction_score), 2) as satisfaction_moyenne,
               COUNT(p.performance_id) as nombre_evaluations
        FROM agents a
        JOIN performances p ON a.agent_id = p.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        ORDER BY satisfaction_moyenne DESC
        LIMIT 5;
        """
    
    # Requ√™te par d√©faut (aper√ßu des performances globales)
    return """
    SELECT a.name, t.team_name,
           SUM(p.calls_made) as appels_total,
           SUM(p.sales) as ventes_total,
           SUM(p.appointments) as rdv_total,
           ROUND(AVG(p.satisfaction_score), 2) as satisfaction_moyenne
    FROM agents a
    JOIN performances p ON a.agent_id = p.agent_id
    JOIN teams t ON a.team_id = t.team_id
    GROUP BY a.agent_id
    ORDER BY ventes_total DESC
    LIMIT 5;
    """

def is_greeting_or_small_talk(text):
    """D√©tecte si le texte est une salutation, une question courte ou autre petite interaction."""
    text = text.lower().strip()
    greetings = ["bonjour", "salut", "hello", "coucou", "hey", "bonsoir", "bon matin"]
    small_talk = ["√ßa va", "comment √ßa va", "comment vas-tu", "comment va", "quoi de neuf"]
    thanks = ["merci", "thanks", "thank you", "je vous remercie", "je te remercie"]
    goodbyes = ["au revoir", "bye", "√† bient√¥t", "√† plus", "adieu", "bonne journ√©e", "salut"]
    help_phrases = ["aide", "help", "besoin d'aide", "aidez-moi", "que peux-tu faire", "comment √ßa marche",
                    "que sais-tu faire", "comment utiliser", "utilisations possibles"]

    for phrase in greetings:
        if phrase in text:
            return True, "greeting"
    for phrase in small_talk:
        if phrase in text:
            return True, "small_talk"
    for phrase in thanks:
        if phrase in text:
            return True, "thanks"
    for phrase in goodbyes:
        if phrase in text:
            return True, "goodbye"
    for phrase in help_phrases:
        if phrase in text:
            return True, "help"
    if len(text.split()) < 4:
        return True, "short_question"
    return False, None

def get_simple_response(type_message):
    """G√©n√®re une r√©ponse courte en fonction du type de message simple."""
    hour = datetime.now().hour
    if type_message == "greeting":
        if 5 <= hour < 12:
            responses = [
                "Bonjour ! Je suis l√† pour vous aider √† analyser vos donn√©es. Voici ce que je peux faire :\n\n" +
                "1. Analyser les performances des agents et des √©quipes\n" +
                "2. V√©rifier l'atteinte des objectifs\n" +
                "3. Examiner les retards et l'assiduit√©\n" +
                "4. Analyser les bonus et r√©compenses\n" +
                "5. √âtudier la satisfaction client\n\n" +
                "Que souhaitez-vous savoir ?",
                
                "Bonjour ! Je peux vous aider √† explorer vos KPIs. Par exemple, vous pouvez me demander :\n\n" +
                "- Combien d'agents avons-nous ?\n" +
                "- Quels sont nos meilleurs agents ?\n" +
                "- Comment performent nos √©quipes ?\n" +
                "- Qui a re√ßu le plus de bonus ?\n\n" +
                "Quelle information recherchez-vous ?"
            ]
        elif 12 <= hour < 18:
            responses = [
                "Bon apr√®s-midi ! Je suis l√† pour vous aider √† analyser vos donn√©es. Voici ce que je peux faire :\n\n" +
                "1. Analyser les performances des agents et des √©quipes\n" +
                "2. V√©rifier l'atteinte des objectifs\n" +
                "3. Examiner les retards et l'assiduit√©\n" +
                "4. Analyser les bonus et r√©compenses\n" +
                "5. √âtudier la satisfaction client\n\n" +
                "Que souhaitez-vous savoir ?",
                
                "Bon apr√®s-midi ! Je peux vous aider √† explorer vos KPIs. Par exemple, vous pouvez me demander :\n\n" +
                "- Combien d'agents avons-nous ?\n" +
                "- Quels sont nos meilleurs agents ?\n" +
                "- Comment performent nos √©quipes ?\n" +
                "- Qui a re√ßu le plus de bonus ?\n\n" +
                "Quelle information recherchez-vous ?"
            ]
        else:
            responses = [
                "Bonsoir ! Je suis l√† pour vous aider √† analyser vos donn√©es. Voici ce que je peux faire :\n\n" +
                "1. Analyser les performances des agents et des √©quipes\n" +
                "2. V√©rifier l'atteinte des objectifs\n" +
                "3. Examiner les retards et l'assiduit√©\n" +
                "4. Analyser les bonus et r√©compenses\n" +
                "5. √âtudier la satisfaction client\n\n" +
                "Que souhaitez-vous savoir ?",
                
                "Bonsoir ! Je peux vous aider √† explorer vos KPIs. Par exemple, vous pouvez me demander :\n\n" +
                "- Combien d'agents avons-nous ?\n" +
                "- Quels sont nos meilleurs agents ?\n" +
                "- Comment performent nos √©quipes ?\n" +
                "- Qui a re√ßu le plus de bonus ?\n\n" +
                "Quelle information recherchez-vous ?"
            ]
        return random.choice(responses)
    elif type_message == "small_talk":
        return "Je vais tr√®s bien, merci ! Je suis l√† pour vous aider √† analyser vos donn√©es. Que souhaitez-vous savoir sur vos KPIs ?"
    elif type_message == "thanks":
        return "Je vous en prie ! N'h√©sitez pas si vous avez d'autres questions sur vos KPIs."
    elif type_message == "goodbye":
        return "Au revoir ! N'h√©sitez pas √† revenir si vous avez besoin d'analyser vos donn√©es."
    elif type_message == "help":
        return (
            "Je suis votre assistant KPIs et DATA. Voici ce que je peux faire :\n\n"
            "1. Analyser les performances des agents et des √©quipes\n"
            "2. V√©rifier l'atteinte des objectifs\n"
            "3. Examiner les retards et l'assiduit√©\n"
            "4. Analyser les bonus et r√©compenses\n"
            "5. √âtudier la satisfaction client\n\n"
            "Par exemple, vous pouvez me demander :\n"
            "- Combien d'agents avons-nous ?\n"
            "- Quels sont nos meilleurs agents ?\n"
            "- Comment performent nos √©quipes ?\n"
            "- Qui a re√ßu le plus de bonus ?"
        )
    elif type_message == "short_question":
        return (
            "Je peux vous aider √† analyser vos donn√©es, mais j'ai besoin de plus de d√©tails. Par exemple, vous pouvez me demander :\n\n"
            "- Combien d'agents avons-nous ?\n"
            "- Quels sont nos meilleurs agents ?\n"
            "- Comment performent nos √©quipes ?\n"
            "- Qui a re√ßu le plus de bonus ?\n\n"
            "Quelle information recherchez-vous pr√©cis√©ment ?"
        )
    else:
        return (
            "Je suis l√† pour vous aider √† analyser vos donn√©es. Voici ce que je peux faire :\n\n"
            "1. Analyser les performances des agents et des √©quipes\n"
            "2. V√©rifier l'atteinte des objectifs\n"
            "3. Examiner les retards et l'assiduit√©\n"
            "4. Analyser les bonus et r√©compenses\n"
            "5. √âtudier la satisfaction client\n\n"
            "Que souhaitez-vous savoir ?"
        )

def get_gemini_response(prompt, max_retries=3, backoff_factor=2):
    """G√©n√®re une r√©ponse en utilisant l'API OpenAI."""
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Vous √™tes un assistant sp√©cialis√© dans l'analyse de donn√©es et la g√©n√©ration de requ√™tes SQL."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt == max_retries - 1:
                st.error(f"Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}")
                return "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse. Veuillez r√©essayer."
            time.sleep(backoff_factor ** attempt)

@st.cache_resource
def load_open_source_model():
    """Charge et met en cache le mod√®le open source GPT-Neo via Hugging Face."""
    from transformers import AutoTokenizer, AutoModelForCausalLM
    model_name = "EleutherAI/gpt-neo-2.7B"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    return tokenizer, model

def get_open_source_response(prompt, max_new_tokens=150):
    """
    Obtient une r√©ponse en utilisant le mod√®le open source GPT-Neo.
    """
    try:
        tokenizer, model = load_open_source_model()
        inputs = tokenizer(prompt, return_tensors="pt")
        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=True, temperature=0.7)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response
    except Exception as e:
        return "Erreur: Impossible d'obtenir une r√©ponse du mod√®le open source. " + str(e)

def get_sql_prompt(schema, chat_history, question):
    """Cr√©e le prompt pour g√©n√©rer une requ√™te SQL √† partir d'une question."""
    template = """
    Vous √™tes un expert SQL. Convertissez cette question en une requ√™te SQL pr√©cise.
    
    Sch√©ma de la base de donn√©es:
    {schema}
    
    Historique des conversations:
    {chat_history}
    
    Question utilisateur: {question}
    
    R√©pondez uniquement avec la requ√™te SQL sans explication.
    """
    return template.format(
        schema=schema,
        chat_history=format_chat_history(chat_history),
        question=question
    )

def get_nl_response_prompt(schema, question, sql_query, sql_result):
    """Cr√©e le prompt pour transformer le r√©sultat SQL en r√©ponse naturelle."""
    template = """
    Transformer le r√©sultat SQL ci-dessous en une r√©ponse claire en fran√ßais.
    
    Sch√©ma de la base de donn√©es:
    {schema}
    
    Question originale: {question}
    
    Requ√™te SQL ex√©cut√©e:
    {sql_query}
    
    R√©sultat de la requ√™te:
    {sql_result}
    
    Expliquez les r√©sultats de mani√®re simple et claire. Si le r√©sultat est vide, indiquez-en la raison.
    """
    return template.format(
        schema=schema,
        question=question,
        sql_query=sql_query,
        sql_result=sql_result
    )

def generate_simple_response(question, sql_result):
    """
    G√©n√®re une r√©ponse simplifi√©e en langage naturel √† partir du r√©sultat SQL.
    Cette fonction analyse la cha√Æne r√©sultat pour identifier les informations cl√©s.
    """
    try:
        lines = sql_result.strip().split('\n')
        # Si la requ√™te concerne le comptage des agents
        if "nombre_agents" in sql_result and len(lines) == 2:
            count = lines[1].strip()
            return f"Il y a {count} agents au total dans le centre d'appels."
        
        # Pour les performances (top ou low performers)
        if ("top" in question or "meilleur" in question) or ("low" in question or "pire" in question):
            agents_list = []
            for i in range(1, min(6, len(lines))):
                cols = lines[i].split(',')
                if len(cols) >= 4:
                    agents_list.append(f"{cols[1].strip()} ({cols[3].strip()})")
            if "top" in question or "meilleur" in question:
                return "Voici les meilleurs agents:\n\n" + "\n".join(f"{idx+1}. {agent}" for idx, agent in enumerate(agents_list))
            else:
                return "Voici les agents avec les performances les plus faibles:\n\n" + "\n".join(f"{idx+1}. {agent}" for idx, agent in enumerate(agents_list))
        
        # Pour les performances des √©quipes
        if "team_name" in sql_result and "nombre_agents" in sql_result and len(lines) > 1:
            teams_performance = []
            for i in range(1, min(4, len(lines))):
                cols = lines[i].split(',')
                if len(cols) >= 3:
                    team_name = cols[0].strip()
                    agents_count = cols[1].strip()
                    total_sales = cols[2].strip()
                    teams_performance.append(f"{team_name}: {total_sales} ventes avec {agents_count} agents")
            return "Performances des √©quipes:\n\n" + "\n".join(teams_performance)
        
        # Pour les objectifs atteints
        if "objectif" in question and "atteint" in sql_result:
            achieved = sum(1 for line in lines[1:] if "Oui" in line)
            total = len(lines) - 1
            return f"{achieved} agents sur {total} ont atteint leurs objectifs de vente."
        
        # Pour la satisfaction client
        if "satisfaction" in question and "score_moyen_satisfaction" in sql_result:
            cols = lines[1].split(',')
            if len(cols) >= 4:
                return f"L'agent avec le meilleur score de satisfaction est {cols[1].strip()} avec un score de {cols[3].strip()}/5."
        
        # R√©ponse g√©n√©rique
        return "Voici les r√©sultats de votre requ√™te. Pour plus de d√©tails, consultez le tableau affich√©."
    except Exception as e:
        return "Voici les r√©sultats de votre requ√™te. Pour plus d'analyse, merci de pr√©ciser votre demande."

def display_sql_result_as_table(result):
    """Convertit le r√©sultat SQL en DataFrame pour l'affichage en tableau."""
    try:
        if isinstance(result, str):
            lines = result.strip().split('\n')
            if len(lines) > 1:
                header = [col.strip() for col in lines[0].split(',')]
                data = [ [cell.strip() for cell in line.split(',')] for line in lines[1:] ]
                df = pd.DataFrame(data, columns=header)
                return df
        return None
    except Exception:
        return None

def get_query_type(question):
    """D√©termine le type de requ√™te √† partir de la question."""
    question = question.lower().strip()
    
    # Mots-cl√©s plus flexibles pour la d√©tection
    performance_keywords = ["perf", "performance", "meilleur", "top", "bon", "excellent", "fort"]
    count_keywords = ["combien", "nombre", "total", "quantit√©"]
    team_keywords = ["√©quipe", "team", "groupe", "service"]
    bonus_keywords = ["bonus", "prime", "r√©compense", "gratification"]
    satisfaction_keywords = ["satisfaction", "client", "√©valuation", "note", "score"]
    attendance_keywords = ["pr√©sence", "absent", "retard", "punctualit√©"]
    
    # D√©tection plus intelligente
    words = question.split()
    performance_count = sum(1 for word in words if word in performance_keywords)
    count_count = sum(1 for word in words if word in count_keywords)
    team_count = sum(1 for word in words if word in team_keywords)
    bonus_count = sum(1 for word in words if word in bonus_keywords)
    satisfaction_count = sum(1 for word in words if word in satisfaction_keywords)
    attendance_count = sum(1 for word in words if word in attendance_keywords)
    
    # D√©cision bas√©e sur le nombre de mots-cl√©s trouv√©s
    if performance_count > 0:
        return "performance"
    elif count_count > 0:
        return "count"
    elif team_count > 0:
        return "team"
    elif bonus_count > 0:
        return "bonus"
    elif satisfaction_count > 0:
        return "satisfaction"
    elif attendance_count > 0:
        return "attendance"
    
    # Si aucun mot-cl√© n'est trouv√©, on essaie de deviner d'apr√®s le contexte
    if any(word in question for word in ["agent", "employ√©", "collaborateur"]):
        return "performance"
    elif any(word in question for word in ["vente", "chiffre", "r√©sultat"]):
        return "performance"
    elif any(word in question for word in ["temps", "heure", "jour"]):
        return "attendance"
    
    return "default"

def format_response(result, query_type):
    """Formate la r√©ponse en fonction du type de requ√™te."""
    try:
        if not result:
            return "Aucun r√©sultat trouv√©."
            
        if isinstance(result, str):
            return result
            
        if isinstance(result, list):
            if not result:
                return "Aucun r√©sultat trouv√©."
                
            if query_type == "count":
                return f"Il y a actuellement {result[0]} agents dans le centre d'appels."
                
            elif query_type == "performance":
                response = "Voici les performances des agents :\n\n"
                for agent in result:
                    if isinstance(agent, (list, tuple)):
                        # V√©rification de la longueur et des valeurs
                        name = str(agent[0]) if len(agent) > 0 and agent[0] is not None else "N/A"
                        team = str(agent[1]) if len(agent) > 1 and agent[1] is not None else "N/A"
                        calls = str(agent[2]) if len(agent) > 2 and agent[2] is not None else "N/A"
                        sales = str(agent[3]) if len(agent) > 3 and agent[3] is not None else "N/A"
                        appointments = str(agent[4]) if len(agent) > 4 and agent[4] is not None else "N/A"
                        satisfaction = str(agent[5]) if len(agent) > 5 and agent[5] is not None else "N/A"
                        
                        response += f"‚Ä¢ {name} ({team}) :\n"
                        response += f"  - Appels : {calls}\n"
                        response += f"  - Ventes : {sales}\n"
                        response += f"  - RDV : {appointments}\n"
                        response += f"  - Satisfaction : {satisfaction}/5\n\n"
                return response
                
            elif query_type == "team":
                response = "Voici les performances par √©quipe :\n\n"
                for team in result:
                    if isinstance(team, (list, tuple)):
                        name = str(team[0]) if len(team) > 0 and team[0] is not None else "N/A"
                        agents = str(team[1]) if len(team) > 1 and team[1] is not None else "N/A"
                        sales = str(team[2]) if len(team) > 2 and team[2] is not None else "N/A"
                        satisfaction = str(team[3]) if len(team) > 3 and team[3] is not None else "N/A"
                        
                        response += f"‚Ä¢ {name} :\n"
                        response += f"  - Nombre d'agents : {agents}\n"
                        response += f"  - Ventes totales : {sales}\n"
                        response += f"  - Satisfaction moyenne : {satisfaction}/5\n\n"
                return response
                
        return str(result)
    except Exception as e:
        return f"Une erreur s'est produite lors du formatage de la r√©ponse : {str(e)}"

def generate_sql_query(question, query_type):
    """G√©n√®re la requ√™te SQL appropri√©e selon le type de question."""
    if query_type == "count":
        return "SELECT COUNT(*) FROM agents;"
        
    elif query_type == "performance":
        return """
        SELECT a.name, t.team_name,
               SUM(p.calls_made) as appels_total,
               SUM(p.sales) as ventes_total,
               SUM(p.appointments) as rdv_total,
               ROUND(AVG(p.satisfaction_score), 2) as satisfaction_moyenne
        FROM agents a
        JOIN performances p ON a.agent_id = p.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        ORDER BY ventes_total DESC
        LIMIT 5;
        """
        
    elif query_type == "team":
        return """
        SELECT t.team_name,
               COUNT(DISTINCT a.agent_id) as nombre_agents,
               SUM(p.sales) as ventes_total,
               ROUND(AVG(p.satisfaction_score), 2) as satisfaction_moyenne
        FROM teams t
        JOIN agents a ON t.team_id = a.team_id
        JOIN performances p ON a.agent_id = p.agent_id
        GROUP BY t.team_id
        ORDER BY ventes_total DESC;
        """
        
    elif query_type == "bonus":
        return """
        SELECT a.name, t.team_name,
               COUNT(b.bonus_id) as nombre_bonus,
               SUM(b.bonus_amount) as montant_total
        FROM agents a
        JOIN bonuses b ON a.agent_id = b.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        ORDER BY montant_total DESC
        LIMIT 5;
        """
        
    elif query_type == "satisfaction":
        return """
        SELECT a.name, t.team_name,
               ROUND(AVG(p.satisfaction_score), 2) as satisfaction_moyenne,
               COUNT(p.performance_id) as nombre_evaluations
        FROM agents a
        JOIN performances p ON a.agent_id = p.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        HAVING nombre_evaluations >= 10
        ORDER BY satisfaction_moyenne DESC
        LIMIT 5;
        """
        
    elif query_type == "attendance":
        return """
        SELECT a.name, t.team_name,
               COUNT(att.attendance_id) as jours_travailles,
               SUM(CASE WHEN att.is_present = 0 THEN 1 ELSE 0 END) as absences,
               SUM(att.tardiness_minutes) as minutes_retard_total
        FROM agents a
        JOIN attendance att ON a.agent_id = att.agent_id
        JOIN teams t ON a.team_id = t.team_id
        GROUP BY a.agent_id
        ORDER BY minutes_retard_total DESC
        LIMIT 5;
        """
    
    return None

# Ajout de la gestion de l'historique
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

def get_contextual_response(question, chat_history):
    """G√©n√®re une r√©ponse contextuelle en fonction de l'historique de la conversation."""
    # Analyse du contexte de la conversation
    context = " ".join([msg["content"] for msg in chat_history[-3:]])  # Derniers 3 messages
    
    # D√©tection du type de conversation
    if any(word in question.lower() for word in ["bonjour", "salut", "hello", "coucou"]):
        return "Bonjour ! Je suis votre assistant pour l'analyse des donn√©es. Comment puis-je vous aider aujourd'hui ?"
    
    elif any(word in question.lower() for word in ["merci", "thanks", "thank you"]):
        return "Je vous en prie ! N'h√©sitez pas si vous avez d'autres questions."
    
    elif any(word in question.lower() for word in ["au revoir", "bye", "√† plus"]):
        return "Au revoir ! N'h√©sitez pas √† revenir si vous avez besoin d'autres analyses."
    
    # Si la question est courte ou vague
    if len(question.split()) < 3:
        return "Je peux vous aider √† analyser vos donn√©es, mais j'ai besoin de plus de d√©tails. Par exemple, vous pouvez me demander :\n\n" + \
               "- Combien d'agents avons-nous ?\n" + \
               "- Quels sont nos meilleurs agents ?\n" + \
               "- Comment performent nos √©quipes ?\n" + \
               "- Qui a re√ßu le plus de bonus ?\n\n" + \
               "Quelle information recherchez-vous pr√©cis√©ment ?"
    
    return None

def process_user_input(user_input):
    """Traite l'entr√©e utilisateur et retourne une r√©ponse appropri√©e."""
    try:
        # V√©rification de la r√©ponse contextuelle
        contextual_response = get_contextual_response(user_input, st.session_state.chat_history)
        if contextual_response:
            return contextual_response
            
        # V√©rification si c'est une salutation ou une petite conversation
        is_small_talk, talk_type = is_greeting_or_small_talk(user_input)
        if is_small_talk:
            return get_simple_response(talk_type)
            
        # R√©cup√©ration du sch√©ma de la base de donn√©es
        schema = get_schema(db)
        
        # D√©termination du type de requ√™te avec une analyse plus approfondie
        query_type = get_query_type(user_input)
        
        # G√©n√©ration de la requ√™te SQL avec v√©rification
        sql_query = generate_sql_query(user_input, query_type)
        if not sql_query:
            return "Je n'ai pas pu comprendre votre demande. Pouvez-vous reformuler votre question ?"
        
        # Ex√©cution de la requ√™te avec gestion des erreurs
        try:
            result = execute_sql_query(sql_query)
        except Exception as e:
            return f"Une erreur s'est produite lors de l'ex√©cution de la requ√™te : {str(e)}"
        
        # V√©rification du r√©sultat
        if not result:
            return "Aucun r√©sultat trouv√© pour votre requ√™te. Voulez-vous essayer avec des crit√®res diff√©rents ?"
        
        # Formatage de la r√©ponse avec v√©rification des donn√©es
        try:
            formatted_response = format_response(result, query_type)
        except Exception as e:
            return f"Une erreur s'est produite lors du formatage de la r√©ponse : {str(e)}"
        
        # Ajout d'une analyse contextuelle enrichie
        if query_type == "performance":
            if "top" in user_input.lower() or "meilleur" in user_input.lower():
                formatted_response += "\n\nüìä Analyse approfondie des performances :\n"
                formatted_response += "- Ces agents se distinguent par leurs excellentes performances en termes de ventes et de satisfaction client.\n"
                formatted_response += "- Leur taux de conversion est sup√©rieur √† la moyenne de l'√©quipe.\n"
                formatted_response += "- Ils maintiennent un niveau de satisfaction client √©lev√© malgr√© un volume d'appels important.\n"
                formatted_response += "- Leur capacit√© √† convertir les appels en rendez-vous est remarquable.\n\n"
                formatted_response += "üí° Recommandations strat√©giques :\n"
                formatted_response += "- √âtudier leurs m√©thodes de travail pour les partager avec l'√©quipe.\n"
                formatted_response += "- Organiser des sessions de partage d'exp√©rience mensuelles.\n"
                formatted_response += "- Mettre en place un syst√®me de mentorat avec ces agents.\n"
                formatted_response += "- R√©compenser leurs performances exceptionnelles.\n"
            elif "faible" in user_input.lower() or "bas" in user_input.lower():
                formatted_response += "\n\nüìä Analyse approfondie des performances :\n"
                formatted_response += "- Ces agents pourraient b√©n√©ficier d'un accompagnement suppl√©mentaire.\n"
                formatted_response += "- Leur taux de conversion est inf√©rieur √† la moyenne de l'√©quipe.\n"
                formatted_response += "- La satisfaction client n√©cessite une attention particuli√®re.\n"
                formatted_response += "- Leur volume d'appels pourrait √™tre optimis√©.\n\n"
                formatted_response += "üí° Plan d'action recommand√© :\n"
                formatted_response += "- Mettre en place un plan d'accompagnement personnalis√©.\n"
                formatted_response += "- Organiser des sessions de formation cibl√©es.\n"
                formatted_response += "- Assigner un mentor parmi les meilleurs agents.\n"
                formatted_response += "- D√©finir des objectifs progressifs et atteignables.\n"
        
        elif query_type == "team":
            formatted_response += "\n\nüìä Analyse comparative des √©quipes :\n"
            formatted_response += "- Comparaison d√©taill√©e des performances entre les √©quipes.\n"
            formatted_response += "- Identification des points forts et axes d'am√©lioration.\n"
            formatted_response += "- Analyse de la r√©partition des ressources et des effectifs.\n"
            formatted_response += "- √âvaluation de la coh√©rence des performances dans le temps.\n\n"
            formatted_response += "üí° Strat√©gies d'am√©lioration :\n"
            formatted_response += "- Organiser des ateliers de partage entre √©quipes.\n"
            formatted_response += "- Mettre en place un syst√®me de mentorat inter-√©quipes.\n"
            formatted_response += "- Harmoniser les m√©thodes de travail entre les √©quipes.\n"
            formatted_response += "- Cr√©er des objectifs communs pour favoriser la collaboration.\n"
        
        elif query_type == "bonus":
            formatted_response += "\n\nüìä Analyse d√©taill√©e des bonus :\n"
            formatted_response += "- Distribution des bonus par √©quipe et par agent.\n"
            formatted_response += "- Impact des bonus sur la motivation et les performances.\n"
            formatted_response += "- √âquit√© dans la distribution des r√©compenses.\n"
            formatted_response += "- Corr√©lation entre les bonus et les r√©sultats.\n\n"
            formatted_response += "üí° Optimisation du syst√®me de bonus :\n"
            formatted_response += "- R√©viser la politique de bonus pour plus d'√©quit√©.\n"
            formatted_response += "- Mettre en place un syst√®me de r√©compenses plus transparent.\n"
            formatted_response += "- Cr√©er des objectifs clairs pour l'obtention des bonus.\n"
            formatted_response += "- Diversifier les types de r√©compenses.\n"
        
        return formatted_response
        
    except Exception as e:
        return f"D√©sol√©, une erreur inattendue s'est produite : {str(e)}. Veuillez r√©essayer avec une autre formulation."

def display_thinking_animation():
    """Affiche une animation de r√©flexion."""
    st.markdown("""
        <div class="thinking">
            <div class="thinking-dots">
                <div class="thinking-dot"></div>
                <div class="thinking-dot"></div>
                <div class="thinking-dot"></div>
            </div>
        </div>
    """, unsafe_allow_html=True)

# === Configuration de l'interface Streamlit ===
st.markdown('<h1 class="main-title">üìä Assistant KPIs</h1>', unsafe_allow_html=True)
st.markdown("""
    <div class="subtitle">
        Interrogez votre base de donn√©es en langage naturel pour obtenir des analyses d√©taill√©es de vos KPIs.
        Notre assistant intelligent vous aide √† comprendre vos donn√©es et √† prendre des d√©cisions √©clair√©es.
    </div>
""", unsafe_allow_html=True)

# Initialisation de la session
if 'messages' not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "assistant",
        "content": "Bonjour ! Je suis votre assistant KPIs. Je peux vous aider √† analyser :\n\n"
                  "üìà Les performances des agents et des √©quipes\n"
                  "üéØ L'atteinte des objectifs\n"
                  "‚è∞ Les retards et l'assiduit√©\n"
                  "üí∞ Les bonus et r√©compenses\n"
                  "üòä La satisfaction client\n\n"
                  "Que souhaitez-vous savoir ?"
    })

# Affichage des messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Ajout d'un timestamp pour chaque message
        timestamp = datetime.now().strftime("%H:%M")
        
        # Style diff√©rent selon le type de message
        if message["role"] == "user":
            st.markdown(f"""
                <div class="chat-message user">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                        <strong style="color: #007acc;">Vous</strong>
                        <span class="timestamp">{timestamp}</span>
                    </div>
                    <div style="line-height: 1.6; color: #d4d4d4;">
                        {message['content']}
                    </div>
                </div>
            """, unsafe_allow_html=True)
        else:
            # Pour les messages de l'assistant, ajout de boutons d'action
            st.markdown(f"""
                <div class="chat-message assistant">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                        <strong style="color: #4ec9b0;">Assistant KPIs</strong>
                        <span class="timestamp">{timestamp}</span>
                    </div>
                    <div style="line-height: 1.6; color: #d4d4d4;">
                        {message['content']}
                    </div>
                    <div style="display: flex; gap: 0.5rem; margin-top: 1rem;">
                        <button class="action-button">
                            <span style="color: #007acc;">üìä</span> Voir les d√©tails
                        </button>
                        <button class="action-button">
                            <span style="color: #4ec9b0;">üì•</span> Exporter
                        </button>
                    </div>
                </div>
            """, unsafe_allow_html=True)

# Zone de saisie utilisateur avec placeholder am√©lior√©
if prompt := st.chat_input("Posez votre question ici... (ex: 'Quels sont nos meilleurs agents ?')"):
    # Ajout du message utilisateur
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        timestamp = datetime.now().strftime("%H:%M")
        st.markdown(f"""
            <div class="chat-message user">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                    <strong style="color: #007acc;">Vous</strong>
                    <span class="timestamp">{timestamp}</span>
                </div>
                <div style="line-height: 1.6; color: #d4d4d4;">
                    {prompt}
                </div>
            </div>
        """, unsafe_allow_html=True)

    # R√©ponse de l'assistant avec animation de r√©flexion
    with st.chat_message("assistant"):
        # Afficher l'animation de r√©flexion
        thinking_placeholder = st.empty()
        thinking_placeholder.markdown("""
            <div class="thinking">
                <div class="thinking-dots">
                    <div class="thinking-dot"></div>
                    <div class="thinking-dot"></div>
                    <div class="thinking-dot"></div>
                </div>
            </div>
        """, unsafe_allow_html=True)
        
        # Traitement de la r√©ponse
        response = process_user_input(prompt)
        
        # Remplacer l'animation par la r√©ponse
        thinking_placeholder.empty()
        timestamp = datetime.now().strftime("%H:%M")
        st.markdown(f"""
            <div class="chat-message assistant">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                    <strong style="color: #4ec9b0;">Assistant KPIs</strong>
                    <span class="timestamp">{timestamp}</span>
                </div>
                <div style="line-height: 1.6; color: #d4d4d4;">
                    {response}
                </div>
                <div style="display: flex; gap: 0.5rem; margin-top: 1rem;">
                    <button class="action-button">
                        <span style="color: #007acc;">üìä</span> Voir les d√©tails
                    </button>
                    <button class="action-button">
                        <span style="color: #4ec9b0;">üì•</span> Exporter
                    </button>
                </div>
            </div>
        """, unsafe_allow_html=True)
        
        # Ajout de la r√©ponse √† l'historique
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.session_state.chat_history.append({"role": "assistant", "content": response})

# Barre lat√©rale
with st.sidebar:
    st.title("üìä Statistiques Rapides")
    col1, col2, col3 = st.columns(3)
    col1.markdown('<div class="sidebar-metric"><div class="sidebar-metric-title">Agents</div><div class="sidebar-metric-value">42</div></div>', unsafe_allow_html=True)
    col2.markdown('<div class="sidebar-metric"><div class="sidebar-metric-title">√âquipes</div><div class="sidebar-metric-value">5</div></div>', unsafe_allow_html=True)
    col3.markdown('<div class="sidebar-metric"><div class="sidebar-metric-title">Satisfaction</div><div class="sidebar-metric-value">4.2/5</div></div>', unsafe_allow_html=True)
    st.markdown("---")
    st.subheader("üí° Exemples de questions")
    examples = [
        "Quels sont nos meilleurs agents ?",
        "Comment √©volue la performance moyenne ?",
        "Quelle √©quipe a la meilleure performance ?",
        "Comparer les performances des √©quipes"
    ]
    for ex in examples:
        if st.button(ex, key=f"ex_{ex}"):
            if 'messages' not in st.session_state:
                st.session_state.messages = []
            st.session_state.messages.append({"role": "user", "content": ex, "time": datetime.now().strftime("%H:%M")})
            response = None
            try:
                response = st.session_state.get('openai_response', None)
            except Exception:
                pass
            if not response:
                response = "[R√©ponse IA ou BDD √† venir]"
            st.session_state.messages.append({"role": "assistant", "content": response, "time": datetime.now().strftime("%H:%M")})
            st.session_state.prompt = ""
            st.experimental_rerun()
    st.markdown("---")
    st.subheader("üõ†Ô∏è Outils")
    st.button("Exporter l'historique")
    st.button("G√©n√©rer un rapport")
    st.button("Param√®tres")
    st.markdown("---")
    st.subheader("‚ùì Aide")
    st.info("Posez des questions pr√©cises pour des r√©ponses pertinentes. Utilisez des crit√®res sp√©cifiques. Combinez plusieurs filtres.")

# ========================
# CONNEXION BDD (SQLite)
# ========================
def get_db_connection():
    try:
        conn = sqlite3.connect("call_center_full_extended.db")
        return conn
    except Exception as e:
        return None

# ========================
# LOGIQUE IA + BDD
# ========================
def ask_openai(prompt, api_key):
    try:
        openai.api_key = api_key
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": "Tu es un assistant expert en analyse de donn√©es business et KPIs."},
                      {"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Erreur OpenAI : {e}"

def kpi_sql_response(question, conn):
    # Ici, tu peux faire du NLP ou du matching pour g√©n√©rer une requ√™te SQL selon la question
    # Exemple simple :
    q = question.lower()
    if "meilleurs agents" in q:
        sql = "SELECT name, team_id, SUM(sales) as ventes FROM performances JOIN agents ON performances.agent_id = agents.agent_id GROUP BY performances.agent_id ORDER BY ventes DESC LIMIT 3;"
    elif "performance moyenne" in q:
        sql = "SELECT ROUND(AVG(sales),2) as moyenne_ventes, ROUND(AVG(satisfaction_score),2) as satisfaction FROM performances;"
    elif "meilleure performance" in q and "√©quipe" in q:
        sql = "SELECT team_id, SUM(sales) as ventes, ROUND(AVG(satisfaction_score),2) as satisfaction FROM performances GROUP BY team_id ORDER BY ventes DESC LIMIT 1;"
    elif "comparer les performances des √©quipes" in q:
        sql = "SELECT team_id, SUM(sales) as ventes, ROUND(AVG(satisfaction_score),2) as satisfaction FROM performances GROUP BY team_id ORDER BY ventes DESC;"
    else:
        return None, None
    try:
        df = None
        if conn:
            df = conn.execute(sql).fetchall()
        return sql, df
    except Exception as e:
        return sql, f"Erreur SQL : {e}"

# ========================
# MAIN : TITRE ET SOUS-TITRE
# ========================
st.markdown("<h1 style='color:#007acc;'>Assistant KPIs</h1>", unsafe_allow_html=True)
st.caption("Analysez vos donn√©es de performance en temps r√©el. Posez vos questions en langage naturel.")

# ========================
# INITIALISATION DE L'HISTORIQUE
# ========================
if 'messages' not in st.session_state:
    st.session_state.messages = []

# ========================
# AFFICHAGE DU CHAT (BULLES)
# ========================
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f'<div class="user-bubble">{msg["content"]}<div class="timestamp">{msg.get("time", "")}</div></div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="assistant-bubble">{msg["content"]}<div class="timestamp">{msg.get("time", "")}</div></div>', unsafe_allow_html=True)
        col1, col2 = st.columns([1,1])
        with col1:
            st.button("Voir les d√©tails", key=f"details_{msg.get('time', '')}")
        with col2:
            st.button("Exporter", key=f"export_{msg.get('time', '')}")

# ========================
# ZONE DE SAISIE UTILISATEUR
# ========================
prompt = st.text_input("Posez votre question ici... (ex: 'Quels sont nos meilleurs agents ?')", value=st.session_state.get("prompt", ""))
if st.button("Envoyer"):
    if prompt.strip():
        st.session_state.messages.append({"role": "user", "content": prompt, "time": datetime.now().strftime("%H:%M")})
        # --- LOGIQUE IA + BDD ---
        conn = get_db_connection()
        sql, result = kpi_sql_response(prompt, conn)
        if sql and result:
            # On formate le r√©sultat pour l'envoyer √† OpenAI
            result_str = str(result)
            ai_prompt = f"Question : {prompt}\n\nRequ√™te SQL ex√©cut√©e : {sql}\n\nR√©sultat brut : {result_str}\n\nExplique ce r√©sultat de fa√ßon claire et synth√©tique pour un manager business."
            response = ask_openai(ai_prompt, OPENAI_API_KEY)
        else:
            # Si pas de SQL, on demande directement √† OpenAI
            response = ask_openai(prompt, OPENAI_API_KEY)
        st.session_state.messages.append({"role": "assistant", "content": response, "time": datetime.now().strftime("%H:%M")})
        st.session_state.prompt = ""
    st.experimental_rerun()
